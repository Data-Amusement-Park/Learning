# EM算法

最大期望算法（Expectation-maximization algorithm，又译为期望最大化算法），是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐性变量。

最大期望算法经过两个步骤交替进行计算：

1. 第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；
2. 第二步是最大化（M），最大化在E步上求得的最大似然值来计算参数的值。M步上找到的参数估计值被用于下一个E步计算中，这个过程不断交替进行。

#### 理解过程
利用极大似然概率估计参数，当观测数据X受另一个隐变量Z影响时，求解过程中，将变得非常复杂，甚至不可得到解析解。求解时需要用全概率公式展开Z的影响，取对数后求和项中的ln项中又包含了求和项，几乎无法再完成求导。

$$
l(\theta) = \prod_{i=1}^N p(x_{i}|\theta)
$$

$$
p(X) = \sum_{i=1}^n p(z_{i})p(X|z_{i}) 
$$

参数$\theta$并不影响$p(Z)$。($\theta$不同会影响Z，但$\theta$是客观的，也就是说Z的分布唯一，例如抽取男女时会因身高分布而抽取的比例不同，但抽取后就变成一定的了，如果过多考虑就远离了该话题讨论的范围)

$$
{\rm ln} \ l(\theta) = \sum_{i=1}^N {\rm ln} \sum_{j=1}^n p(z_{j}|\theta)p(x_{i}|z_{j}, \theta) = \sum_{i=1}^N {\rm ln} \sum_{j=1}^n p(z_{j})p(x_{i}|\theta_{j})
$$

- 举例：估计男女各自身高的正态分布参数，但不知样本中个体的男女；估计两枚硬币朝上的概率，但不知样本是AB哪枚硬币所抛出的。

#### 根本：

* 隐变量将观测数据划分成了多个部分，且各个部分数据对应的分布参数 $\theta$是不同的（但模型相同，仅参数不同）（不知模型是否可不同？，例如一个符合正态分布、一个符合均匀分布）。
* 要想利用MLE估计参数，必须首先知道数据的因变量身份，即$p(Z)$，$p(z|x)$；而要知道数据是怎么划分（身份）$p(z|x)$，最大似然估计（或借助贝叶斯公式），就必须先知道各部分数据的分布$p(x|z)$，即参数$\theta$。即后验和似然概率均不知道。


#### EM算法的思想：
1. 给θ自主规定个初值；
2. 根据给定观测数据和当前的参数θ，求未观测数据z的条件概率分布的期望；
3. 上一步中z已经求出来了，于是根据极大似然估计求最优的θ；
4. 因为第二步和第三步的结果可能不是最优的，所以重复第二步和第三步，直到收敛。

---
#### 参考
[【机器学习基础】EM算法](https://blog.csdn.net/u010834867/article/details/90762296)
[如何通俗理解EM算法](https://blog.csdn.net/v_july_v/article/details/81708386)