
# 前要
* 目的：定向网络数据爬取与网页解析
* 理念：The Website is the API...

## 库
* requests：自动爬取HTML页面，自动网络请求提交
* robots.txt：网络爬虫排除标准
* beautiful soup： 解析HTML页面
* re：正则表达式，提取页面关键信息
* scrapy*: 专业网络爬虫框架

## HTML/CSS/JS等基础知识


