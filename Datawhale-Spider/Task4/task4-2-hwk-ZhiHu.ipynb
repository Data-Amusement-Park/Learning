{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4-2 hwk 知乎爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "链接如下\n",
    "<br>https://www.zhihu.com/search?q=Datawhale&utm_content=search_history&type=content\n",
    "\n",
    "<br>用requests库实现，不能用selenium网页自动化\n",
    "\n",
    "<br>**提示**：\n",
    "\n",
    "* <br>该链接需要登录，可通过github等，搜索知乎登录的代码实现，并理解其中的逻辑，此任务允许复制粘贴代码\n",
    "* <br>与上面ajax加载类似，这次的ajax加载需要用requests完成爬取，最终存储样式随意，但是通过Chrome的开发者工具，分析出ajax的流程需要写出来\n",
    "\n",
    "![1585811566%281%29.png](1585811566%281%29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在zhihu_login_master的文件夹下运行zhihu_login.py文件**<br>\n",
    "**然后会得到一个cookies.txt，复制到此目录下即可运行下列代码**<br>\n",
    "https://github.com/zkqiang/Zhihu-Login 我使用的代码在此，他的README.md里有详细解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zhuhu_login已经die\n",
    "!python zhihu-login-master/zhihu_login.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from http import cookiejar\n",
    "Session=requests.session()\n",
    "Session.cookies = cookiejar.LWPCookieJar(filename='./cookies.txt')\n",
    "Session.cookies.load(ignore_discard=True)\n",
    "Session.headers={\n",
    "            'Host': 'www.zhihu.com',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                          '(KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'\n",
    "        }\n",
    "r=Session.get(\"https://www.zhihu.com/search?q=Datawhale&utm_content=search_history&type=content\")\n",
    "r.encoding=\"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "compiler=re.compile('\"next\":\"(https:\\\\\\\\u002F\\\\\\\\u002Fapi.zhihu.com\\\\\\\\u002Fsearch_v3.*?)\"')\n",
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsObj=BeautifulSoup(r.text,\"lxml\")\n",
    "url=compiler.findall(r.text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote\n",
    "url=unquote(url,encoding=\"utf-8\", errors='replace')\n",
    "url=url.replace(\"\\\\u002F\",\"/\")\n",
    "search_hash_id=re.search(\"search_hash_id=(.*?)&show_all_topics\",url).group(1)\n",
    "search_hash_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=20\n",
    "lc_idx=21\n",
    "for i in range(5):\n",
    "    r=Session.get(\"https://www.zhihu.com/api/v4/search_v3?t=general&q=Datawhale&correction=1&offset={offset}&limit=20&lc_idx={lc_idx}&show_all_topics=0&search_hash_id={search_hash_id}&vertical_info=0%2C0%2C1%2C0%2C0%2C0%2C0%2C0%2C0%2C0\".format(**{\"offset\":offset+i*20,\"lc_idx\":lc_idx+i*20,\"search_hash_id\":search_hash_id}))\n",
    "    r.encoding=\"utf-8\"\n",
    "    print(r.json())\n",
    "    print(\"\\n\"*20)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}