{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1 赛题理解\n",
    "\n",
    "## 1. 赛题介绍\n",
    "### 1.1 赛题概况\n",
    "预测二手车的交易价格。数据集报名后可见并可下载，该数据来自某交易平台的二手车交易记录，总数据量超过40w，包含31列变量信息，其中15列为匿名变量。为了保证比赛的公平性，将会从中抽取15万条作为训练集，5万条作为测试集A，5万条作为测试集B，同时会对name、model、brand和regionCode等信息进行脱敏。\n",
    "\n",
    "### 1.2 数据概况\n",
    "---\n",
    "**train.csv**\n",
    "* SaleID - 销售样本ID\n",
    "* name - 汽车编码\n",
    "* regDate - 汽车注册时间\n",
    "* model - 车型编码\n",
    "* brand - 品牌\n",
    "* bodyType - 车身类型\n",
    "* fuelType - 燃油类型\n",
    "* gearbox - 变速箱\n",
    "* power - 汽车功率\n",
    "* kilometer - 汽车行驶公里\n",
    "* notRepairedDamage - 汽车有尚未修复的损坏\n",
    "* regionCode - 看车地区编码\n",
    "* seller - 销售方\n",
    "* offerType - 报价类型\n",
    "* creatDate - 广告发布时间\n",
    "* price - 汽车价格\n",
    "* v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14' 【匿名特征，包含v0-14在内15个匿名特征】\n",
    "　\n",
    " \n",
    "数字全都脱敏处理，都为label encoding形式，即数字形式\n",
    "\n",
    "Tip:匿名特征，就是未告知数据列所属的性质的特征列。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 数据读取pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train data shape: (150000, 31)\nTestA data shape: (50000, 30)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## 1) 载入训练集和测试集；\n",
    "path = './data/'\n",
    "Train_data = pd.read_csv(path+'used_car_train_20200313.csv', sep=' ')\n",
    "Test_data = pd.read_csv(path+'used_car_testA_20200313.csv', sep=' ')\n",
    "\n",
    "print('Train data shape:',Train_data.shape)\n",
    "print('TestA data shape:',Test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n0       0     736  20040402   30.0      6       1.0       0.0      0.0     60   \n1       1    2262  20030301   40.0      1       2.0       0.0      0.0      0   \n2       2   14874  20040403  115.0     15       1.0       0.0      0.0    163   \n3       3   71865  19960908  109.0     10       0.0       0.0      1.0    193   \n4       4  111080  20120103  110.0      5       1.0       0.0      0.0     68   \n\n   kilometer  ...       v_5       v_6       v_7       v_8       v_9      v_10  \\\n0       12.5  ...  0.235676  0.101988  0.129549  0.022816  0.097462 -2.881803   \n1       15.0  ...  0.264777  0.121004  0.135731  0.026597  0.020582 -4.900482   \n2       12.5  ...  0.251410  0.114912  0.165147  0.062173  0.027075 -4.846749   \n3       15.0  ...  0.274293  0.110300  0.121964  0.033395  0.000000 -4.509599   \n4        5.0  ...  0.228036  0.073205  0.091880  0.078819  0.121534 -1.896240   \n\n       v_11      v_12      v_13      v_14  \n0  2.804097 -2.420821  0.795292  0.914762  \n1  2.096338 -1.030483 -1.722674  0.245522  \n2  1.803559  1.565330 -0.832687 -0.229963  \n3  1.285940 -0.501868 -2.438353 -0.478699  \n4  0.910783  0.931110  2.834518  1.923482  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SaleID</th>\n      <th>name</th>\n      <th>regDate</th>\n      <th>model</th>\n      <th>brand</th>\n      <th>bodyType</th>\n      <th>fuelType</th>\n      <th>gearbox</th>\n      <th>power</th>\n      <th>kilometer</th>\n      <th>...</th>\n      <th>v_5</th>\n      <th>v_6</th>\n      <th>v_7</th>\n      <th>v_8</th>\n      <th>v_9</th>\n      <th>v_10</th>\n      <th>v_11</th>\n      <th>v_12</th>\n      <th>v_13</th>\n      <th>v_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>736</td>\n      <td>20040402</td>\n      <td>30.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60</td>\n      <td>12.5</td>\n      <td>...</td>\n      <td>0.235676</td>\n      <td>0.101988</td>\n      <td>0.129549</td>\n      <td>0.022816</td>\n      <td>0.097462</td>\n      <td>-2.881803</td>\n      <td>2.804097</td>\n      <td>-2.420821</td>\n      <td>0.795292</td>\n      <td>0.914762</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2262</td>\n      <td>20030301</td>\n      <td>40.0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0.264777</td>\n      <td>0.121004</td>\n      <td>0.135731</td>\n      <td>0.026597</td>\n      <td>0.020582</td>\n      <td>-4.900482</td>\n      <td>2.096338</td>\n      <td>-1.030483</td>\n      <td>-1.722674</td>\n      <td>0.245522</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14874</td>\n      <td>20040403</td>\n      <td>115.0</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>163</td>\n      <td>12.5</td>\n      <td>...</td>\n      <td>0.251410</td>\n      <td>0.114912</td>\n      <td>0.165147</td>\n      <td>0.062173</td>\n      <td>0.027075</td>\n      <td>-4.846749</td>\n      <td>1.803559</td>\n      <td>1.565330</td>\n      <td>-0.832687</td>\n      <td>-0.229963</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>71865</td>\n      <td>19960908</td>\n      <td>109.0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>193</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0.274293</td>\n      <td>0.110300</td>\n      <td>0.121964</td>\n      <td>0.033395</td>\n      <td>0.000000</td>\n      <td>-4.509599</td>\n      <td>1.285940</td>\n      <td>-0.501868</td>\n      <td>-2.438353</td>\n      <td>-0.478699</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>111080</td>\n      <td>20120103</td>\n      <td>110.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>68</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>0.228036</td>\n      <td>0.073205</td>\n      <td>0.091880</td>\n      <td>0.078819</td>\n      <td>0.121534</td>\n      <td>-1.896240</td>\n      <td>0.910783</td>\n      <td>0.931110</td>\n      <td>2.834518</td>\n      <td>1.923482</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 预测指标\n",
    "### 2.1 本赛题评价标准\n",
    "\n",
    "**本赛题的评价标准为MAE(Mean Absolute Error):**\n",
    "\n",
    "$$\n",
    "MAE=\\frac{\\sum_{i=1}^{n}\\left|y_{i}-\\hat{y}_{i}\\right|}{n}\n",
    "$$\n",
    "其中$y_{i}$代表第$i$个样本的真实值，其中$\\hat{y}_{i}$代表第$i$个样本的预测值。\n",
    "\n",
    "### 2.2 一般问题评价指标说明\n",
    "\n",
    "**什么是评估指标：**\n",
    "\n",
    ">评估指标即是我们对于一个模型效果的数值型量化。（有点类似与对于一个商品评价打分，而这是针对于模型效果和理想效果之间的一个打分）\n",
    "\n",
    "一般来说分类和回归问题的评价指标有如下一些形式：\n",
    "\n",
    "#### 分类算法常见的评估指标如下：\n",
    "* 对于二类分类器/分类算法，评价指标主要有accuracy，Precision，Recall，F-score，Pr曲线，ROC-AUC曲线。\n",
    "* 对于多类分类器/分类算法，评价指标主要有accuracy，宏平均和微平均，F-score。\n",
    "\n",
    "#### 对于回归预测类常见的评估指标如下:\n",
    "* 平均绝对误差（Mean Absolute Error，MAE），均方误差（Mean Squared Error，MSE），平均绝对百分误差（Mean Absolute Percentage Error，MAPE），均方根误差（Root Mean Squared Error）， R2（R-Square）\n",
    "\n",
    "**平均绝对误差**\n",
    "**平均绝对误差（Mean Absolute Error，MAE）**:平均绝对误差，其能更好地反映预测值与真实值误差的实际情况，其计算公式如下：\n",
    "$$\n",
    "MAE=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right|\n",
    "$$\n",
    "\n",
    "**均方误差**\n",
    "**均方误差（Mean Squared Error，MSE）**,均方误差,其计算公式为：\n",
    "$$\n",
    "MSE=\\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\n",
    "$$\n",
    "\n",
    "**R2（R-Square）的公式为**：\n",
    "残差平方和：\n",
    "$$\n",
    "SS_{res}=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\n",
    "$$\n",
    "总平均值:\n",
    "$$\n",
    "SS_{tot}=\\sum\\left(y_{i}-\\overline{y}_{i}\\right)^{2}\n",
    "$$\n",
    "\n",
    "其中$\\overline{y}$表示$y$的平均值\n",
    "得到$R^2$表达式为：\n",
    "$$\n",
    "R^{2}=1-\\frac{SS_{res}}{SS_{tot}}=1-\\frac{\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{\\sum\\left(y_{i}-\\overline{y}\\right)^{2}}\n",
    "$$\n",
    "$R^2$用于度量因变量的变异中可由自变量解释部分所占的比例，取值范围是 0~1，$R^2$越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近，用x的变化来解释y值变化的部分就越多,回归的拟合程度就越好。所以$R^2$也称为拟合优度（Goodness of Fit）的统计量。\n",
    "\n",
    "$y_{i}$表示真实值，$\\hat{y}_{i}$表示预测值，$\\overline{y}_{i}$表示样本均值。得分越高拟合效果越好。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 评价指标计算示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ACC: 0.75\n"
    }
   ],
   "source": [
    "## accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 1, 0, 1]\n",
    "y_true = [0, 1, 1, 1]\n",
    "print('ACC:',accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision 1.0\nRecall 0.5\nF1-score: 0.6666666666666666\n"
    }
   ],
   "source": [
    "## Precision,Recall,F1-score\n",
    "from sklearn import metrics\n",
    "y_pred = [0, 1, 0, 0]\n",
    "y_true = [0, 1, 0, 1]\n",
    "print('Precision',metrics.precision_score(y_true, y_pred))\n",
    "print('Recall',metrics.recall_score(y_true, y_pred))\n",
    "print('F1-score:',metrics.f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AUC socre: 0.75\n"
    }
   ],
   "source": [
    "## AUC\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = np.array([0, 0, 1, 1])\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "print('AUC socre:',roc_auc_score(y_true, y_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE: 0.2871428571428571\nRMSE: 0.5358571238146014\nMAE: 0.4142857142857143\nMAPE: 0.1461904761904762\n"
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# MAPE需要自己实现\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true))\n",
    "\n",
    "y_true = np.array([1.0, 5.0, 4.0, 3.0, 2.0, 5.0, -3.0])\n",
    "y_pred = np.array([1.0, 4.5, 3.8, 3.2, 3.0, 4.8, -2.2])\n",
    "\n",
    "# MSE\n",
    "print('MSE:',metrics.mean_squared_error(y_true, y_pred))\n",
    "# RMSE\n",
    "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_true, y_pred)))\n",
    "# MAE\n",
    "print('MAE:',metrics.mean_absolute_error(y_true, y_pred))\n",
    "# MAPE\n",
    "print('MAPE:',mape(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "R2-score: 0.9486081370449679\n"
    }
   ],
   "source": [
    "## R2-score\n",
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "print('R2-score:',r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 赛题分析\n",
    "1. 此题为传统的数据挖掘问题，通过数据科学以及机器学习深度学习的办法来进行建模得到结果。\n",
    "2. 此题是一个典型的回归问题。\n",
    "3. 主要应用xgb、lgb、catboost，以及pandas、numpy、matplotlib、seabon、sklearn、keras等等数据挖掘常用库或者框架来进行数据挖掘任务。\n",
    "4. 通过EDA来挖掘数据的联系和自我熟悉数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task2 EDA-数据探索性分析\n",
    "Exploratory Data Analysis\n",
    "\n",
    "## 2.1 EDA目标\n",
    "* EDA的价值主要在于熟悉数据集，了解数据集，对数据集进行验证来确定所获得数据集可以用于接下来的机器学习或者深度学习使用。\n",
    "\n",
    "* 当了解了数据集之后我们下一步就是要去了解变量间的相互关系以及变量与预测值之间的存在关系。\n",
    "\n",
    "* 引导数据科学从业者进行数据处理以及特征工程的步骤,使数据集的结构和特征集让接下来的预测问题更加可靠。\n",
    "\n",
    "* 完成对于数据的探索性分析，并对于数据进行一些图表或者文字总结并打卡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 载入各种数据科学以及可视化库\n",
    "- 数据科学库 pandas、numpy、scipy；\n",
    "- 可视化库 matplotlib、seabon；\n",
    "- 其他；\n",
    "\n",
    "Tip: 库安装pip install，\n",
    "\n",
    "例如 pip install pandas  -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#导入warnings包，利用过滤器来实现忽略警告语句。\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 载入数据\n",
    "- 载入训练集和测试集；\n",
    "- 简略观察数据(head()+shape)；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 载入训练集和测试集；\n",
    "path = './data/'\n",
    "Train_data = pd.read_csv(path+'used_car_train_20200313.csv', sep=' ')\n",
    "Test_data = pd.read_csv(path+'used_car_testA_20200313.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) 简略观察数据(head()+shape)\n",
    "Train_data.head().append(Train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data.head().append(Test_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 总览数据概况\n",
    "1. 通过describe()来熟悉数据的相关统计量。describe种有每列的统计量，个数count、平均值mean、方差std、最小值min、中位数25% 50% 75% 、以及最大值 看这个信息主要是瞬间掌握数据的大概的范围以及每个值的异常值的判断，比如有的时候会发现999 9999 -1 等值这些其实都是nan的另外一种表达方式，有的时候需要注意下\n",
    "2. 通过info()来熟悉数据类型。info 通过info来了解数据每列的type，有助于了解是否存在除了nan以外的特殊符号异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 通过describe()来熟悉数据的相关统计量\n",
    "Train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) 通过info()来熟悉数据类型\n",
    "Train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 判断数据缺失和异常\n",
    "- 查看每列的存在nan情况\n",
    "- 异常值检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 查看每列的存在nan情况\n",
    "Train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan可视化\n",
    "missing = Train_data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 了解预测值的分布\n",
    "- 总体分布概况（无界约翰逊分布等）\n",
    "- 查看skewness and kurtosis\n",
    "- 查看预测值的具体频数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 特征分为类别特征和数字特征，并对类别特征查看unique分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7  数字特征分析\n",
    "- 相关性分析\n",
    "- 查看几个特征得 偏度和峰值\n",
    "- 每个数字特征得分布可视化\n",
    "- 数字特征相互之间的关系可视化\n",
    "- 多变量互相回归关系可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8  类型特征分析\n",
    "- unique分布\n",
    "- 类别特征箱形图可视化\n",
    "- 类别特征的小提琴图可视化\n",
    "- 类别特征的柱形图可视化类别\n",
    "- 特征的每个类别频数可视化(count_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 用pandas_profiling生成数据报告"
   ]
  }
 ]
}